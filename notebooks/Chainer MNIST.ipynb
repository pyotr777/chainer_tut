{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chainer MNIST tutorial\n",
    "\n",
    "http://docs.chainer.org/en/latest/tutorial/basic.html#example-multi-layer-perceptron-on-mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use model from Keras tutorial\n",
    "\n",
    "https://elitedatascience.com/keras-tutorial-deep-learning-in-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import chainer\n",
    "import chainer.functions as F\n",
    "import chainer.links as L\n",
    "from chainer import training\n",
    "from chainer.training import extensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(123)  # for reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from urllib import urlretrieve\n",
    "\n",
    "def download(filename, source='http://yann.lecun.com/exdb/mnist/'):\n",
    "    print(\"Downloading %s\" % filename)\n",
    "    urlretrieve(source + filename, filename)\n",
    "\n",
    "# We then define functions for loading MNIST images and labels.\n",
    "# For convenience, they also download the requested files if needed.\n",
    "import gzip\n",
    "\n",
    "def load_mnist_images(filename):\n",
    "    if not os.path.exists(filename):\n",
    "        download(filename)\n",
    "    # Read the inputs in Yann LeCun's binary format.\n",
    "    with gzip.open(filename, 'rb') as f:\n",
    "        data = np.frombuffer(f.read(), np.uint8, offset=16)\n",
    "    # The inputs are vectors now, we reshape them to monochrome 2D images,\n",
    "    # following the shape convention: (examples, channels, rows, columns)\n",
    "    data = data.reshape(-1, 1, 28, 28)\n",
    "    # The inputs come as bytes, we convert them to float32 in range [0,1].\n",
    "    # (Actually to range [0, 255/256], for compatibility to the version\n",
    "    # provided at http://deeplearning.net/data/mnist/mnist.pkl.gz.)\n",
    "    return data / np.float32(256)\n",
    "\n",
    "def load_mnist_labels(filename):\n",
    "    if not os.path.exists(filename):\n",
    "        download(filename)\n",
    "    # Read the labels in Yann LeCun's binary format.\n",
    "    with gzip.open(filename, 'rb') as f:\n",
    "        data = np.frombuffer(f.read(), np.uint8, offset=8)\n",
    "    # The labels are vectors of integers now, that's exactly what we want.\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = load_mnist_images('train-images-idx3-ubyte.gz')\n",
    "y_train = load_mnist_labels('train-labels-idx1-ubyte.gz')\n",
    "X_test = load_mnist_images('t10k-images-idx3-ubyte.gz')\n",
    "y_test = load_mnist_labels('t10k-labels-idx1-ubyte.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 1, 28, 28)\n",
      "(60000,)\n",
      "(10000, 1, 28, 28)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "print X_train.shape\n",
    "print y_train.shape\n",
    "print X_test.shape\n",
    "print y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def plotSet(X,Y,N=0):\n",
    "    if N==0:\n",
    "        N = len(X)\n",
    "    total = N\n",
    "    if (len(X) < N):\n",
    "        N = len(X)\n",
    "    if (len(Y) < N):\n",
    "        N = len(Y)\n",
    "    max_in_row = 25\n",
    "    M = 1\n",
    "    if N > max_in_row:\n",
    "        M = int(math.ceil(N/max_in_row))\n",
    "        N = max_in_row\n",
    "    w = math.floor(1/N*1000)/1000    \n",
    "    #w=0.1\n",
    "    h = math.floor(1/(M) *1000)/1000\n",
    "    #h=0.3\n",
    "    #print N,M,w,h\n",
    "    pad = 0\n",
    "    fig = plt.figure(figsize=(N/1.5, M), dpi=120)    \n",
    "    for j in range(M):\n",
    "        for i in range(N):\n",
    "            n = i+(j*N)+1 \n",
    "            if n > total:\n",
    "                break\n",
    "            l = pad+(i+1)*(w+pad)\n",
    "            b = pad+(j)*(h+pad)\n",
    "            #print n,l,b,Y[n-1]\n",
    "            #a = fig.add_axes([l, b, w, h])\n",
    "            a = fig.add_subplot(M,N,n)\n",
    "            a.imshow(X[n-1][0])\n",
    "            a.axis('off')\n",
    "            a.set_title(str(Y[n-1]),fontsize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA+AAAACBCAYAAABAZ9AfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fcf0661be10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotSet(X_train,y_train,15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert labels to 10 distinct class labels (one-hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'numpy.uint8'>\n",
      "<type 'numpy.int32'>\n"
     ]
    }
   ],
   "source": [
    "print type(y_train[0])\n",
    "y_train = y_train.astype(np.int32)\n",
    "y_test = y_test.astype(np.int32)\n",
    "print type(y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Network definition Multi Layer Perceptron (MLP)\n",
    "class MLP(chainer.Chain):\n",
    "\n",
    "    def __init__(self, n_units=128, n_out=10):\n",
    "        super(MLP, self).__init__()\n",
    "        with self.init_scope():\n",
    "            # the size of the inputs to each layer will be inferred\n",
    "            self.l1 = L.Linear(None, n_units)  # n_in -> n_units\n",
    "            self.l2 = L.Linear(None, n_units)  # n_units -> n_units\n",
    "            self.l3 = L.Linear(None, n_out)  # n_units -> n_out\n",
    "\n",
    "    def __call__(self, x):\n",
    "        h1 = F.relu(self.l1(x))\n",
    "        h2 = F.relu(self.l2(h1))\n",
    "        return self.l3(h2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model definition\n",
    "class SampleModel(chainer.Chain):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(SampleModel, self).__init__(\n",
    "            l1 = L.Convolution2D(None, 32, (3,3)),\n",
    "            l2 = L.Convolution2D(None, 32, (3,3)),\n",
    "            l6 = L.Linear(None, 128),\n",
    "            l8 = L.Linear(None, 10),\n",
    "        )\n",
    "\n",
    "    def __call__(self, x):\n",
    "        h = F.tanh(self.l1(x))\n",
    "        h = F.relu(self.l2(h))\n",
    "        h = F.max_pooling_2d(h, (2,2))\n",
    "        #h = F.flatten(h)\n",
    "        h = F.reshape(h,(h.shape[0],h.shape[1]*h.shape[2]*h.shape[3]))\n",
    "        #h = F.relu(self.l6(h5))\n",
    "        h = F.dropout(h, 0.25)\n",
    "        h = self.l8(h)\n",
    "        h = F.relu(h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from chainer.datasets import tuple_dataset\n",
    "training_dataset = tuple_dataset.TupleDataset(X_train, y_train)\n",
    "test_dataset = tuple_dataset.TupleDataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'chainer.datasets.tuple_dataset.TupleDataset'>\n",
      "60000\n"
     ]
    }
   ],
   "source": [
    "print type(training_dataset)\n",
    "print len(training_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batchsize = 64\n",
    "epoch = 2\n",
    "samples=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.SampleModel'>\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "#model_class_name = \"MLP\"\n",
    "model_class_name = \"SampleModel\"\n",
    "model_class = getattr(sys.modules[__name__], model_class_name)\n",
    "model = model_class()\n",
    "print type(model)\n",
    "\n",
    "model = L.Classifier(model, lossfun = F.softmax_cross_entropy)\n",
    "optimizer = chainer.optimizers.AdaGrad(lr=0.01, eps=0.0005)\n",
    "optimizer.setup(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from chainer.training import extensions\n",
    "\n",
    "train_iter = chainer.iterators.SerialIterator(training_dataset[:samples], batchsize)\n",
    "test_iter = chainer.iterators.SerialIterator(test_dataset, batchsize,\n",
    "                                                 repeat=False, shuffle=False)\n",
    "updater = training.StandardUpdater(train_iter, optimizer)\n",
    "trainer = training.Trainer(updater, (epoch, 'epoch'), out=\".\")\n",
    "# Evaluate the model with the test dataset for each epoch\n",
    "trainer.extend(extensions.Evaluator(test_iter, model))\n",
    "trainer.extend(extensions.LogReport())\n",
    "trainer.extend(extensions.PrintReport(\n",
    "    ['epoch',  'main/loss', 'validation/main/loss', 'main/accuracy','validation/main/accuracy', 'elapsed_time']))\n",
    "# Save two plot images to the result dir\n",
    "if extensions.PlotReport.available():\n",
    "    trainer.extend(\n",
    "        extensions.PlotReport(['main/loss', 'validation/main/loss', 'main/accuracy', 'validation/main/accuracy'],\n",
    "                              'epoch', file_name='learning_curve.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Reporter(extensions.LogReport):\n",
    "    \n",
    "    train_acc = []\n",
    "    train_loss = []\n",
    "    test_acc = []\n",
    "    \n",
    "    def __call__(self, trainer):\n",
    "        keys = self._keys\n",
    "        observation = trainer.observation\n",
    "        summary = self._summary\n",
    "        #print \"Debug info from Reporter\"\n",
    "        print observation\n",
    "        \n",
    "        ##\n",
    "        ## TODO:\n",
    "        ## Conver from Variable class to float\n",
    "        self.train_acc.append(observation[\"main/accuracy\"].data)\n",
    "        self.train_loss.append(observation[\"main/loss\"].data[0])\n",
    "        self.test_acc.append(None)\n",
    "        #print keys\n",
    "        if keys is None:\n",
    "            summary.add(observation)\n",
    "        else:\n",
    "            summary.add({k: observation[k] for k in keys if k in observation})\n",
    "\n",
    "        if self._trigger(trainer):\n",
    "            updater = trainer.updater\n",
    "            print updater.epoch, updater.iteration, trainer.elapsed_time\n",
    "            self.test_acc[-1] = observation[\"validation/main/accuracy\"].data[0]\n",
    "            \n",
    "    def get_data(self):\n",
    "        return {\"train_acc\":self.train_acc, \"train_loss\":self.train_loss, \"test_acc\":self.test_acc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_reporter = Reporter()\n",
    "trainer.extend(my_reporter)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch       main/loss   validation/main/loss  main/accuracy  validation/main/accuracy  elapsed_time\n",
      "{'main/loss': variable(2.273726224899292), 'main/accuracy': variable(0.171875)}\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-2e7505ede742>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmy_reporter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/chainer/training/trainer.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    297\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentry\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mextensions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrigger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m                             \u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentry\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mextensions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-3de6e23c14dd>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, trainer)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;31m#print \"Debug info from Reporter\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0mobservation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_acc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"main/accuracy\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"main/loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_acc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array"
     ]
    }
   ],
   "source": [
    "trainer.run()\n",
    "data = my_reporter.get_data()\n",
    "print data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_loss_accuracy_org(train_loss, test_loss, train_acc, test_acc, train_points, validation_points) :    \n",
    "    if train_points is None:\n",
    "        train_points = np.arange(0,len(train_loss))        \n",
    "    if validation_points is None:\n",
    "        step = len(train_loss)/len(test_loss)\n",
    "        print len(train_loss),\"batches\",len(test_loss),\"epochs, step\",step\n",
    "        validation_points = np.arange(step,step*len(test_loss)+1,step)        \n",
    "    fig = plt.figure(figsize=(15, 10))\n",
    "    ax1 = fig.add_subplot(111)\n",
    "    ax2 = ax1.twinx()\n",
    "    ax1.plot(train_points, train_loss, 'r-',label= \"loss_train\",alpha=0.3)\n",
    "    ax1.plot(validation_points, test_loss, 'r.-',label= \"loss_test\")\n",
    "    ax2.plot(train_points, train_acc, 'b-',label= \"acc_train\",alpha=0.7)\n",
    "    ax2.plot(validation_points, test_acc, 'b.-',label= \"acc_test\")\n",
    "    ax1.set_ylim([0,2.5])\n",
    "    ax1.set_xlabel('batch')\n",
    "    ax1.set_ylabel('loss')\n",
    "    ax2.set_ylabel('accuracy')\n",
    "\n",
    "    ax2.set_ylim([0,1])\n",
    "    ax1.legend(loc='center right')\n",
    "    ax2.legend(loc='best')\n",
    "    ax1.minorticks_on()\n",
    "    ax1.grid(which=\"both\")\n",
    "    \n",
    "def plot_loss_accuracy(train_loss, test_loss, train_acc, test_acc) :    \n",
    "    print len(train_acc)\n",
    "    x = np.arange(0,len(train_acc))\n",
    "    fig = plt.figure(figsize=(15, 10))\n",
    "    ax1 = fig.add_subplot(111)\n",
    "    ax2 = ax1.twinx()\n",
    "    if train_loss is not None:\n",
    "        ax1.plot(x, train_loss, 'r-',label= \"loss_train\",alpha=0.3)\n",
    "    if test_loss is not None:\n",
    "        ax1.plot(x, test_loss, 'r.-',label= \"loss_test\")\n",
    "    if train_acc is not None:\n",
    "        ax2.plot(x, train_acc, 'b-',label= \"acc_train\",alpha=0.7)\n",
    "    if test_acc is not None:\n",
    "        ax2.plot(x, test_acc, 'b.-',label= \"acc_test\")\n",
    "    ax1.set_ylim([0,2.5])\n",
    "    ax1.set_xlabel('batch')\n",
    "    ax1.set_ylabel('loss')\n",
    "    ax2.set_ylabel('accuracy')\n",
    "\n",
    "    ax2.set_ylim([0,1])\n",
    "    ax1.legend(loc='center right')\n",
    "    ax2.legend(loc='best')\n",
    "    ax1.minorticks_on()\n",
    "    ax1.grid(which=\"both\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print type(data[\"train_loss\"])\n",
    "train_loss = np.asarray(data[\"train_loss\"])\n",
    "#train_loss = train_loss.astype(np.float32)\n",
    "print type(train_loss[0])\n",
    "plot_loss_accuracy(data[\"train_loss\"], None, data[\"train_acc\"], data[\"test_acc\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def decodeNum(x):\n",
    "    i = []\n",
    "    for xi in x:\n",
    "        ni = np.argmax(xi)\n",
    "        i.append(ni)\n",
    "    return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Pick random indexes\n",
    "test_indexes = np.random.randint(0,y_test.shape[0], batchsize)\n",
    "x = X_test[test_indexes]\n",
    "t = y_test[test_indexes]\n",
    "\n",
    "# Predictions for random elements\n",
    "y = model.predictor(x)\n",
    "y = y.data\n",
    "# y has predictions as probabilities\n",
    "h = np.asarray(decodeNum(y))\n",
    "# h has predictions as numbers\n",
    "\n",
    "# Find incorrect predictions\n",
    "errors = []\n",
    "for i in range(len(h)):\n",
    "    if h[i] != t[i]:        \n",
    "        errors.append(i)\n",
    "print \"Have\",len(errors),\"errors\"\n",
    "# errors has indexes of incorrect redictions\n",
    "for i in errors:\n",
    "    print h[i],\"â‰ \", t[i]\n",
    "\n",
    "# plot images and predictions (incorrect)\n",
    "if len(errors) > 0:\n",
    "    plotSet(x[errors],h[errors])\n",
    "\n",
    "    # Plot probabilities\n",
    "    y_err = y[errors]\n",
    "    for i in range(len(y_err)):\n",
    "        fig = plt.figure()\n",
    "        plt.bar(range(len(y_err[i])), y_err[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
